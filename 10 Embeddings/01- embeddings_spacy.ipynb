{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Word Embeddings`\n",
    "* In this notebook we will go through word embeddings using deep learning, we will not train a new model we will use pre-trained ones as training a new one will cost a lot.\n",
    "* We will be using `spacy` in this tutorial to demonstrate word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "# Upgrade pip, install spacy, and download model\n",
    "$ pip install -U pip setuptools wheel\n",
    "$ pip install -U spacy\n",
    "$ python -m spacy download en_core_web_md\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "cmap = sns.light_palette('blue', as_cmap=True)\n",
    "import spacy\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using spaCy model\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed_size -> 300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 4.5855 ,  2.4556 , -8.5233 , -6.0595 , -0.44879, -2.5409 ,\n",
       "        4.3721 ,  1.4889 ,  4.6075 ,  6.7933 ], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding size\n",
    "embed_size = len(nlp('car').vector)\n",
    "print('embed_size ->', embed_size)\n",
    "\n",
    "# Use it like that (first 10 values)\n",
    "nlp('car').vector[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on samples\n",
    "words = ['cat', 'dog', 'car', 'bird', 'eagle']\n",
    "vectors = [nlp(word).vector for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_39659_row0_col0, #T_39659_row1_col1, #T_39659_row2_col2, #T_39659_row3_col3, #T_39659_row4_col4 {\n",
       "  background-color: #0000ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_39659_row0_col1 {\n",
       "  background-color: #3a3afc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_39659_row0_col2 {\n",
       "  background-color: #cfcff4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_39659_row0_col3 {\n",
       "  background-color: #8484f8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_39659_row0_col4 {\n",
       "  background-color: #adadf6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_39659_row1_col0 {\n",
       "  background-color: #3535fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_39659_row1_col2 {\n",
       "  background-color: #aeaef6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_39659_row1_col3 {\n",
       "  background-color: #9b9bf7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_39659_row1_col4 {\n",
       "  background-color: #bebef5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_39659_row2_col0, #T_39659_row2_col3, #T_39659_row2_col4, #T_39659_row4_col1, #T_39659_row4_col2 {\n",
       "  background-color: #f0f0f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_39659_row2_col1 {\n",
       "  background-color: #dedff4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_39659_row3_col0 {\n",
       "  background-color: #8b8bf8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_39659_row3_col1 {\n",
       "  background-color: #b3b3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_39659_row3_col2 {\n",
       "  background-color: #dbdbf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_39659_row3_col4 {\n",
       "  background-color: #6161fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_39659_row4_col0 {\n",
       "  background-color: #c9c9f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_39659_row4_col3 {\n",
       "  background-color: #6b6bfa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_39659\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_39659_level0_col0\" class=\"col_heading level0 col0\" >cat</th>\n",
       "      <th id=\"T_39659_level0_col1\" class=\"col_heading level0 col1\" >dog</th>\n",
       "      <th id=\"T_39659_level0_col2\" class=\"col_heading level0 col2\" >car</th>\n",
       "      <th id=\"T_39659_level0_col3\" class=\"col_heading level0 col3\" >bird</th>\n",
       "      <th id=\"T_39659_level0_col4\" class=\"col_heading level0 col4\" >eagle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_39659_level0_row0\" class=\"row_heading level0 row0\" >cat</th>\n",
       "      <td id=\"T_39659_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_39659_row0_col1\" class=\"data row0 col1\" >0.822082</td>\n",
       "      <td id=\"T_39659_row0_col2\" class=\"data row0 col2\" >0.196986</td>\n",
       "      <td id=\"T_39659_row0_col3\" class=\"data row0 col3\" >0.536937</td>\n",
       "      <td id=\"T_39659_row0_col4\" class=\"data row0 col4\" >0.330381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39659_level0_row1\" class=\"row_heading level0 row1\" >dog</th>\n",
       "      <td id=\"T_39659_row1_col0\" class=\"data row1 col0\" >0.822082</td>\n",
       "      <td id=\"T_39659_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_39659_row1_col2\" class=\"data row1 col2\" >0.325002</td>\n",
       "      <td id=\"T_39659_row1_col3\" class=\"data row1 col3\" >0.456740</td>\n",
       "      <td id=\"T_39659_row1_col4\" class=\"data row1 col4\" >0.268694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39659_level0_row2\" class=\"row_heading level0 row2\" >car</th>\n",
       "      <td id=\"T_39659_row2_col0\" class=\"data row2 col0\" >0.196986</td>\n",
       "      <td id=\"T_39659_row2_col1\" class=\"data row2 col1\" >0.325002</td>\n",
       "      <td id=\"T_39659_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_39659_row2_col3\" class=\"data row2 col3\" >0.153305</td>\n",
       "      <td id=\"T_39659_row2_col4\" class=\"data row2 col4\" >0.069607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39659_level0_row3\" class=\"row_heading level0 row3\" >bird</th>\n",
       "      <td id=\"T_39659_row3_col0\" class=\"data row3 col0\" >0.536937</td>\n",
       "      <td id=\"T_39659_row3_col1\" class=\"data row3 col1\" >0.456740</td>\n",
       "      <td id=\"T_39659_row3_col2\" class=\"data row3 col2\" >0.153305</td>\n",
       "      <td id=\"T_39659_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_39659_row3_col4\" class=\"data row3 col4\" >0.623637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39659_level0_row4\" class=\"row_heading level0 row4\" >eagle</th>\n",
       "      <td id=\"T_39659_row4_col0\" class=\"data row4 col0\" >0.330381</td>\n",
       "      <td id=\"T_39659_row4_col1\" class=\"data row4 col1\" >0.268694</td>\n",
       "      <td id=\"T_39659_row4_col2\" class=\"data row4 col2\" >0.069607</td>\n",
       "      <td id=\"T_39659_row4_col3\" class=\"data row4 col3\" >0.623637</td>\n",
       "      <td id=\"T_39659_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1bfe1d9ed40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get similarity\n",
    "similarities = cosine_similarity(vectors, vectors)\n",
    "pd.DataFrame(similarities, columns=words, index=words).style.background_gradient(cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The vectors generated by `spacy` model is a 300 dimensional vector which is the output of a pre-trained GloVe model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `The same dataset we are working on`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moham\\anaconda3\\envs\\depi\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import random\n",
    "from termcolor import colored\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = fetch_20newsgroups(subset='test', remove=['headers', 'footers', 'quotes'],\n",
    "                         categories=['rec.autos', 'comp.windows.x', \n",
    "                                     'soc.religion.christian', 'rec.sport.baseball'])\n",
    "\n",
    "# Split to X & y\n",
    "X = data.data\n",
    "y = [data.target_names[i] for i in data.target]\n",
    "\n",
    "# Split to train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Vectorizing using spaCy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1268/1268 [00:56<00:00, 22.25it/s]\n",
      "100%|██████████| 318/318 [00:17<00:00, 17.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Empty list for vectorization\n",
    "X_train_vect = np.zeros((len(X_train), embed_size))\n",
    "X_test_vect = np.zeros((len(X_test), embed_size))\n",
    "\n",
    "# Looping over X_train\n",
    "for i, doc in tqdm(enumerate(nlp.pipe(X_train)), total=len(X_train)):\n",
    "    X_train_vect[i, :] = doc.vector\n",
    "\n",
    "for i, doc in tqdm(enumerate(nlp.pipe(X_test)), total=len(X_test)):\n",
    "    X_test_vect[i, :] = doc.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `1. Train a Classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moham\\anaconda3\\envs\\depi\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "y_pred_test = clf.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        comp.windows.x       0.92      0.89      0.90        79\n",
      "             rec.autos       0.87      0.90      0.88        79\n",
      "    rec.sport.baseball       0.91      0.94      0.93        80\n",
      "soc.religion.christian       0.97      0.95      0.96        80\n",
      "\n",
      "              accuracy                           0.92       318\n",
      "             macro avg       0.92      0.92      0.92       318\n",
      "          weighted avg       0.92      0.92      0.92       318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9182389937106918"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_test) # of a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `2. Using Cosine Similarity Get Top Similar (as we did before)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 163\n",
      "True label: \u001b[32mcomp.windows.x\u001b[0m\n",
      "0 nearest label is \u001b[32mcomp.windows.x\u001b[0m similarity: \u001b[33m0.913\u001b[0m\n",
      "1 nearest label is \u001b[32mcomp.windows.x\u001b[0m similarity: \u001b[33m0.911\u001b[0m\n",
      "2 nearest label is \u001b[32mcomp.windows.x\u001b[0m similarity: \u001b[33m0.906\u001b[0m\n",
      "ID: 5\n",
      "True label: \u001b[32mrec.sport.baseball\u001b[0m\n",
      "0 nearest label is \u001b[32mrec.sport.baseball\u001b[0m similarity: \u001b[33m0.979\u001b[0m\n",
      "1 nearest label is \u001b[32mrec.sport.baseball\u001b[0m similarity: \u001b[33m0.978\u001b[0m\n",
      "2 nearest label is \u001b[32mrec.sport.baseball\u001b[0m similarity: \u001b[33m0.978\u001b[0m\n",
      "ID: 68\n",
      "True label: \u001b[32mrec.autos\u001b[0m\n",
      "0 nearest label is \u001b[31mrec.sport.baseball\u001b[0m similarity: \u001b[33m0.967\u001b[0m\n",
      "1 nearest label is \u001b[31msoc.religion.christian\u001b[0m similarity: \u001b[33m0.964\u001b[0m\n",
      "2 nearest label is \u001b[31mrec.sport.baseball\u001b[0m similarity: \u001b[33m0.963\u001b[0m\n",
      "ID: 135\n",
      "True label: \u001b[32msoc.religion.christian\u001b[0m\n",
      "0 nearest label is \u001b[32msoc.religion.christian\u001b[0m similarity: \u001b[33m0.982\u001b[0m\n",
      "1 nearest label is \u001b[32msoc.religion.christian\u001b[0m similarity: \u001b[33m0.981\u001b[0m\n",
      "2 nearest label is \u001b[32msoc.religion.christian\u001b[0m similarity: \u001b[33m0.976\u001b[0m\n",
      "ID: 7\n",
      "True label: \u001b[32mrec.autos\u001b[0m\n",
      "0 nearest label is \u001b[31msoc.religion.christian\u001b[0m similarity: \u001b[33m0.949\u001b[0m\n",
      "1 nearest label is \u001b[31msoc.religion.christian\u001b[0m similarity: \u001b[33m0.948\u001b[0m\n",
      "2 nearest label is \u001b[31msoc.religion.christian\u001b[0m similarity: \u001b[33m0.948\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for i in random.choices(range(0, len(X_test)), k=5):\n",
    "    print(f\"ID: {i}\")\n",
    "    print(\"True label:\", colored(y_test[i], 'green'))\n",
    "    distances = cosine_similarity(X_test_vect[i].reshape(1, embed_size), X_train_vect).flatten()\n",
    "    indices = np.argsort(distances)[::-1]\n",
    "    for _, j in enumerate(indices[:3]):\n",
    "        print(f\"{_} nearest label is {colored(y_train[j], 'green' if y_train[j]==y_test[i] else 'red')}\",\n",
    "             f\"similarity: {colored(round(distances[j], 3), 'yellow')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acccuray Score using cosine simlarity is: 74.214 %\n"
     ]
    }
   ],
   "source": [
    "# List to append in it the predicted of test labels\n",
    "y_pred_test = []\n",
    "\n",
    "# Loop over the entire test dataset\n",
    "for i in range(len(X_test)):\n",
    "    # Compute cosine similarity between the test instance and all training instances\n",
    "    distances = cosine_similarity(X_test_vect[i].reshape(1, embed_size), X_train_vect).flatten()\n",
    "    # Get the indices of the training instances sorted by similarity in descending order\n",
    "    indices = np.argsort(distances)[::-1]\n",
    "    # Get the labels of the three nearest neighbors\n",
    "    nearest_labels = [y_train[j] for j in indices[:3]]\n",
    "    # Determine the most common label among the three nearest neighbors\n",
    "    y_pred_each = Counter(nearest_labels).most_common(1)[0][0]\n",
    "    # Append to list\n",
    "    y_pred_test.append(y_pred_each)\n",
    "\n",
    "# Get Accuracy score\n",
    "acc = accuracy_score(y_test, y_pred_test)\n",
    "print(f'Acccuray Score using cosine simlarity is: {acc*100:.3f} %') # using cosine similarity as a metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `3. Using Euclidean Distance for measuring similarity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 138\n",
      "True label: \u001b[32msoc.religion.christian\u001b[0m\n",
      "0 nearest label is \u001b[32msoc.religion.christian\u001b[0m similarity: \u001b[33m5.068\u001b[0m\n",
      "1 nearest label is \u001b[32msoc.religion.christian\u001b[0m similarity: \u001b[33m6.055\u001b[0m\n",
      "2 nearest label is \u001b[32msoc.religion.christian\u001b[0m similarity: \u001b[33m6.318\u001b[0m\n",
      "ID: 63\n",
      "True label: \u001b[32mrec.sport.baseball\u001b[0m\n",
      "0 nearest label is \u001b[32mrec.sport.baseball\u001b[0m similarity: \u001b[33m6.581\u001b[0m\n",
      "1 nearest label is \u001b[32mrec.sport.baseball\u001b[0m similarity: \u001b[33m10.307\u001b[0m\n",
      "2 nearest label is \u001b[32mrec.sport.baseball\u001b[0m similarity: \u001b[33m10.581\u001b[0m\n",
      "ID: 241\n",
      "True label: \u001b[32msoc.religion.christian\u001b[0m\n",
      "0 nearest label is \u001b[31mrec.sport.baseball\u001b[0m similarity: \u001b[33m5.626\u001b[0m\n",
      "1 nearest label is \u001b[32msoc.religion.christian\u001b[0m similarity: \u001b[33m6.032\u001b[0m\n",
      "2 nearest label is \u001b[31mcomp.windows.x\u001b[0m similarity: \u001b[33m6.277\u001b[0m\n",
      "ID: 291\n",
      "True label: \u001b[32msoc.religion.christian\u001b[0m\n",
      "0 nearest label is \u001b[32msoc.religion.christian\u001b[0m similarity: \u001b[33m6.368\u001b[0m\n",
      "1 nearest label is \u001b[32msoc.religion.christian\u001b[0m similarity: \u001b[33m7.583\u001b[0m\n",
      "2 nearest label is \u001b[32msoc.religion.christian\u001b[0m similarity: \u001b[33m8.085\u001b[0m\n",
      "ID: 62\n",
      "True label: \u001b[32mrec.autos\u001b[0m\n",
      "0 nearest label is \u001b[31mcomp.windows.x\u001b[0m similarity: \u001b[33m12.425\u001b[0m\n",
      "1 nearest label is \u001b[32mrec.autos\u001b[0m similarity: \u001b[33m14.573\u001b[0m\n",
      "2 nearest label is \u001b[32mrec.autos\u001b[0m similarity: \u001b[33m14.999\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for i in random.choices(range(0, len(X_test)), k=5):\n",
    "    print(f\"ID: {i}\")\n",
    "    print(\"True label:\", colored(y_test[i], 'green'))\n",
    "    distances = euclidean_distances(X_test_vect[i].reshape(1, embed_size), X_train_vect).flatten() \n",
    "    indices = np.argsort(distances)\n",
    "    for _, j in enumerate(indices[:3]):\n",
    "        print(f\"{_} nearest label is {colored(y_train[j], 'green' if y_train[j]==y_test[i] else 'red')}\",\n",
    "             f\"similarity: {colored(round(distances[j], 3), 'yellow')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acccuray Score using Euclidean Distance is: 73.899 %\n"
     ]
    }
   ],
   "source": [
    "# List to append in it the predicted of test labels\n",
    "y_pred_test = []\n",
    "\n",
    "# Loop over the entire test dataset\n",
    "for i in range(len(X_test)):\n",
    "  \n",
    "    # Compute euclidean_distances between the test instance and all training instances\n",
    "    distances = euclidean_distances(X_test_vect[i].reshape(1, embed_size), X_train_vect).flatten() \n",
    "    # Get the indices of the training instances sorted by distance in ascending order\n",
    "    indices = np.argsort(distances)\n",
    "    # Get the labels of the three nearest neighbors\n",
    "    nearest_labels = [y_train[j] for j in indices[:3]]\n",
    "    # Determine the most common label among the three nearest neighbors\n",
    "    y_pred_each = Counter(nearest_labels).most_common(1)[0][0]\n",
    "    # Append to list\n",
    "    y_pred_test.append(y_pred_each)\n",
    "\n",
    "# Get Accuracy score\n",
    "acc = accuracy_score(y_test, y_pred_test)\n",
    "print(f'Acccuray Score using Euclidean Distance is: {acc*100:.3f} %') # usign euclidean distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Conclusion`\n",
    "\n",
    "- Word embedding is a very powerful feature specially if you have small data, as your model will make use of the learned features of the word2vec or GloVe model and thus will be able to make better predictions.\n",
    "- Word2vec and GloVe don't count for different context that the same word can have in different sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
